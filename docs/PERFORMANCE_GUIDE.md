# Performance Guide: Chat Loop System

## Overview

This guide provides comprehensive information about the performance characteristics, optimizations, and monitoring capabilities of the Chat Loop System. It covers memory management, performance monitoring, benchmarking, and optimization strategies.

## Performance Architecture

### Core Performance Features

#### 1. Incremental Memory Management

The system implements real-time memory management to prevent memory bloat during long conversations:

```python
def _should_trim_memory(self) -> bool:
    """Check if memory trimming is needed."""
    current_length = len(self.ctx.conversation_history)
    max_safe_size = self.config.max_history_pairs * 2 + 5
    return current_length > max_safe_size * 1.5  # Trigger at 150%
```

**Key Metrics:**

- **Trigger Threshold**: 150% of safe conversation size
- **Trim Level**: 120% of maximum history pairs
- **Performance**: <10ms for trimming operations
- **Memory Efficiency**: 70-90% memory reduction

#### 2. Performance Monitoring System

Comprehensive performance tracking with adaptive logging:

```python
def _monitor_performance(self, operation: str, start_time: float):
    """Monitor operation performance."""
    elapsed = time.time() - start_time
    
    if elapsed > 5.0:      # Slow operations
        logger.warning(f"üêå Slow operation: {operation} took {elapsed:.2f}s")
    elif elapsed > 1.0:     # Moderate operations  
        logger.info(f"‚è±Ô∏è Operation timing: {operation} took {elapsed:.2f}s")
    else:                  # Fast operations
        logger.debug(f"‚ö° Fast operation: {operation} took {elapsed:.2f}s")
```

**Performance Categories:**

- **Fast Operations** (<1s): DEBUG level logging
- **Moderate Operations** (1-5s): INFO level logging
- **Slow Operations** (>5s): WARNING level logging

#### 3. Memory Threshold System

Smart memory management with adaptive thresholds:

| Threshold Type | Value | Purpose |
|---------------|-------|---------|
| **Safe Size** | `max_pairs * 2 + 5` | Normal conversation limit |
| **Trim Trigger** | `safe_size * 1.5` | When to start trimming |
| **Trim Level** | `max_pairs * 1.2` | Where to trim to |
| **Emergency Trim** | `safe_size * 2.0` | Force trim for safety |

#### 4. Caching and Rate Limiting

New in v0.3.0, these features ensure system stability:

- **Embedding Cache**: LRU cache (max 5000 items) for expensive embedding generations.
  - **Hit Time**: <1ms
  - **Save Interval**: Every 100 items (auto-save)
  - **File Permissions**: `0o600` (Owner-only)

- **Rate Limiting**: Token bucket algorithm to prevent abuse.
  - **Overhead**: <0.1ms per check
  - **Impact**: Negligible on valid traffic; blocks abusive traffic instantly.

## Performance Benchmarks

### Operation Timing Benchmarks

| Operation | Expected Time | 95th Percentile | Maximum | Memory Impact |
|-----------|-------------|-----------------|----------|---------------|
| **Input Validation** | 0.1ms | 0.5ms | 1ms | Minimal |
| **Content Sanitization** | 0.2ms | 1ms | 2ms | Minimal |
| **Context Injection** | 5ms | 20ms | 50ms | Low |
| **LLM Invocation** | 500ms | 2000ms | 5000ms | Medium |
| **Tool Execution** | 50ms | 200ms | 1000ms | Varies |
| **Memory Trimming** | 5ms | 20ms | 50ms | Medium |
| **Complete Iteration** | 300ms | 1000ms | 3000ms | Low |

### Memory Usage Benchmarks

| Conversation Size | Memory Usage | Trim Frequency | Efficiency |
|-----------------|--------------|---------------|------------|
| **10 messages** | ~1MB | Never | 100% |
| **50 messages** | ~5MB | Never | 100% |
| **100 messages** | ~10MB | Never | 100% |
| **500 messages** | ~50MB | Every 50 messages | 85% |
| **1000 messages** | ~100MB | Every 25 messages | 80% |
| **5000 messages** | ~500MB | Every 10 messages | 75% |

### Scalability Metrics

| Metric | Small Scale | Medium Scale | Large Scale | Enterprise Scale |
|--------|-------------|--------------|-------------|-----------------|
| **Concurrent Users** | 1-10 | 10-100 | 100-1000 | 1000+ |
| **Messages/Hour** | 100 | 1,000 | 10,000 | 100,000+ |
| **Tools/Iteration** | 1-3 | 1-5 | 1-10 | 1-20 |
| **Memory Usage** | <100MB | <1GB | <10GB | <100GB |
| **CPU Usage** | <5% | <10% | <25% | <50% |

## Performance Optimization Strategies

### 1. Memory Management Optimization

#### For Short Conversations (< 100 messages)

```python
# No special optimization needed
chat_loop = ChatLoop()
# System handles automatically
```

#### For Medium Conversations (100-1000 messages)

```python
# Configure for optimal memory management
config = {
    'max_history_pairs': 100,  # Adjust based on needs
    'trim_threshold': 1.5,     # Keep default
    'safe_trim_level': 1.2      # Keep default
}
```

#### For Long Conversations (1000+ messages)

```python
# Aggressive memory management
config = {
    'max_history_pairs': 50,    # Lower for frequent trimming
    'trim_threshold': 1.3,      # More aggressive trimming
    'safe_trim_level': 1.1      # Keep more trimmed
}
```

### 2. Performance Monitoring Setup

#### Development Environment

```python
import os
import logging

# Enable all monitoring
os.environ['VERBOSE_LOGGING'] = 'true'
os.environ['SHOW_TOKEN_USAGE'] = 'true'
os.environ['SHOW_LLM_REASONING'] = 'true'
os.environ['SHOW_TOOL_DETAILS'] = 'true'

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

#### Production Environment

```python
import os
import logging

# Minimal monitoring for production
os.environ['VERBOSE_LOGGING'] = 'false'
os.environ['SHOW_TOKEN_USAGE'] = 'true'  # For billing/cost tracking
os.environ['SHOW_LLM_REASONING'] = 'false'
os.environ['SHOW_TOOL_DETAILS'] = 'false'

# Production logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### 3. Tool Execution Optimization

#### Sequential Execution (Current)

```python
# Default - safe and reliable
results = []
for tool_call in tool_calls:
    result = execute_tool(tool_call)
    results.append(result)
```

#### Parallel Execution (Future)

```python
# Planned for future versions
import asyncio

async def execute_tools_parallel(tool_calls):
    tasks = [execute_tool(tool_call) for tool_call in tool_calls]
    results = await asyncio.gather(*tasks)
    return results
```

### 4. Context Optimization

#### Automatic Context Management

```python
# System handles automatically based on configuration
chat_loop = ChatLoop()

# Context is automatically managed based on:
# - Context mode (auto/on/off)
# - Available context
# - Performance impact
```

#### Manual Context Control

```python
# For specific performance requirements
class OptimizedChatLoop(ChatLoop):
    def _inject_context(self, user_input: str) -> str:
        # Custom context logic for performance
        if len(user_input) < 100:  # Skip context for short inputs
            return user_input
        return super()._inject_context(user_input)
```

## Performance Monitoring & Alerting

### 1. Real-time Monitoring

#### Performance Statistics Collection

```python
def monitor_performance():
    chat_loop = ChatLoop()
    
    # Collect performance data
    stats = chat_loop._get_performance_stats()
    
    # Alert on high memory usage
    if stats['memory_utilization'] > 0.8:
        trigger_memory_cleanup()
    
    # Alert on slow operations
    if stats.get('last_operation_time', 0) > 5.0:
        alert_slow_operation()
```

#### Memory Leak Detection

```python
def detect_memory_leaks():
    initial_memory = get_memory_usage()
    
    # Run test operations
    for _ in range(100):
        chat_loop.run_iteration("test message")
    
    final_memory = get_memory_usage()
    memory_growth = final_memory - initial_memory
    
    if memory_growth > 10:  # 10MB threshold
        alert_memory_leak(memory_growth)
```

### 2. Performance Dashboards

#### Key Metrics to Track

- **Response Time**: Average, 95th percentile, 99th percentile
- **Memory Usage**: Current, peak, trend
- **Throughput**: Messages per minute, tool executions per minute
- **Error Rate**: Failures per 1000 requests
- **Resource Utilization**: CPU, memory, disk I/O

#### Sample Monitoring Code

```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'memory_usage': [],
            'error_count': 0,
            'request_count': 0
        }
    
    def record_request(self, response_time: float, memory_usage: float, success: bool):
        self.metrics['response_times'].append(response_time)
        self.metrics['memory_usage'].append(memory_usage)
        self.metrics['request_count'] += 1
        
        if not success:
            self.metrics['error_count'] += 1
    
    def get_dashboard_data(self):
        return {
            'avg_response_time': mean(self.metrics['response_times']),
            'p95_response_time': percentile(self.metrics['response_times'], 95),
            'memory_trend': self._calculate_memory_trend(),
            'error_rate': self.metrics['error_count'] / self.metrics['request_count']
        }
```

## Performance Testing

### 1. Load Testing

#### Basic Load Test

```python
import threading
import time
from concurrent.futures import ThreadPoolExecutor

def load_test(num_users: int, duration_seconds: int):
    def simulate_user():
        chat_loop = ChatLoop()
        start_time = time.time()
        
        while time.time() - start_time < duration_seconds:
            response = chat_loop.run_iteration(f"Test message {threading.current_thread().ident}")
            time.sleep(1)  # 1 message per second per user
    
    with ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = [executor.submit(simulate_user) for _ in range(num_users)]
        for future in futures:
            future.result()

# Run load test
load_test(num_users=10, duration_seconds=300)  # 10 users for 5 minutes
```

#### Stress Testing

```python
def stress_test():
    chat_loop = ChatLoop()
    
    # Test with maximum input size
    large_input = "x" * MAX_INPUT_LENGTH
    response = chat_loop.run_iteration(large_input)
    
    # Test with maximum tool calls
    many_tools = [{"name": "test_tool", "args": {}}] * 20
    # ... simulate many tool calls
    
    # Test memory limits
    for i in range(10000):
        chat_loop.run_iteration(f"Stress test message {i}")
```

### 2. Performance Regression Testing

#### Automated Benchmarks

```python
def run_performance_benchmark():
    """Run comprehensive performance benchmarks."""
    results = {}
    
    # Input validation benchmark
    start_time = time.time()
    for _ in range(1000):
        chat_loop._validate_input("test input")
    results['input_validation'] = time.time() - start_time
    
    # Memory management benchmark
    mock_ctx = MagicMock()
    for i in range(1000):
        mock_ctx.conversation_history.append(f"message_{i}")
    
    start_time = time.time()
    chat_loop._trim_conversation_history_incremental()
    results['memory_trimming'] = time.time() - start_time
    
    return results

# Run benchmarks and compare with baselines
current_performance = run_performance_benchmark()
baseline_performance = load_baseline()  # Load from file

for operation, current_time in current_performance.items():
    baseline_time = baseline_performance.get(operation, current_time)
    regression = (current_time - baseline_time) / baseline_time
    
    if regression > 0.1:  # 10% regression threshold
        alert_performance_regression(operation, regression)
```

### 3. Memory Testing

#### Memory Leak Detection

```python
def test_memory_leaks():
    initial_memory = get_memory_usage()
    
    # Run many iterations
    for i in range(10000):
        chat_loop.run_iteration(f"Memory test {i}")
        
        # Check memory every 1000 iterations
        if i % 1000 == 0:
            current_memory = get_memory_usage()
            memory_growth = current_memory - initial_memory
            
            if memory_growth > 50:  # 50MB threshold
                assert False, f"Memory leak detected: {memory_growth}MB growth"
```

#### Memory Efficiency Testing

```python
def test_memory_efficiency():
    chat_loop = ChatLoop()
    mock_ctx = MagicMock()
    
    # Test with various conversation sizes
    for size in [10, 100, 1000, 5000]:
        mock_ctx.conversation_history = [f"message_{i}" for i in range(size)]
        
        start_memory = get_memory_usage()
        chat_loop._trim_conversation_history_incremental()
        end_memory = get_memory_usage()
        
        memory_saved = start_memory - end_memory
        efficiency = memory_saved / start_memory
        
        assert efficiency > 0.5, f"Memory efficiency too low: {efficiency:.2f}"
```

## Performance Tuning

### 1. System Configuration

#### Memory Settings

```python
# Optimal settings for different use cases

# Development/Testing
DEVELOPMENT_CONFIG = {
    'max_history_pairs': 20,
    'trim_threshold': 2.0,      # Less aggressive
    'safe_trim_level': 1.5,     # Keep more history
    'performance_monitoring': True,
    'verbose_logging': True
}

# Production Standard
PRODUCTION_CONFIG = {
    'max_history_pairs': 100,
    'trim_threshold': 1.5,      # Balanced
    'safe_trim_level': 1.2,     # Standard
    'performance_monitoring': True,
    'verbose_logging': False
}

# High Throughput
HIGH_THROUGHPUT_CONFIG = {
    'max_history_pairs': 50,
    'trim_threshold': 1.3,      # More aggressive
    'safe_trim_level': 1.1,     # Keep less history
    'performance_monitoring': True,
    'verbose_logging': False
}
```

#### Performance Tuning

```python
# Tune for specific workloads

class TunedChatLoop(ChatLoop):
    def _should_trim_memory(self) -> bool:
        # Custom threshold for high-throughput scenarios
        current_length = len(self.ctx.conversation_history)
        max_pairs = self.config.max_history_pairs
        # More aggressive trimming for high throughput
        return current_length > max_pairs * 1.2
    
    def _monitor_performance(self, operation: str, start_time: float):
        # Custom monitoring for specific operations
        elapsed = time.time() - start_time
        
        # Custom thresholds
        if elapsed > 2.0:      # Lower threshold for critical operations
            logger.warning(f"Critical slow operation: {operation} took {elapsed:.2f}s")
        
        super()._monitor_performance(operation, start_time)
```

### 2. Resource Optimization

#### CPU Optimization

```python
# Minimize CPU usage

# 1. Cache expensive operations
class OptimizedChatLoop(ChatLoop):
    def __init__(self):
        super().__init__()
        self._context_cache = {}
    
    def _inject_context(self, user_input: str) -> str:
        # Cache context for repeated inputs
        cache_key = hash(user_input)
        if cache_key in self._context_cache:
            return self._context_cache[cache_key]
        
        result = super()._inject_context(user_input)
        self._context_cache[cache_key] = result
        
        # Limit cache size
        if len(self._context_cache) > 1000:
            self._context_cache.clear()
        
        return result

# 2. Async operations for I/O bound tasks
import asyncio

async def async_context_injection(user_input: str) -> str:
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None, 
        original_inject_context, 
        user_input
    )
```

#### Memory Optimization

```python
# Minimize memory usage

class MemoryOptimizedChatLoop(ChatLoop):
    def __init__(self):
        super().__init__()
        self._message_pool = []  # Reuse message objects
    
    def _cleanup_memory(self) -> None:
        # Aggressive memory cleanup
        gc.collect()  # Force garbage collection
        
        # Clear any caches
        if hasattr(self, '_context_cache'):
            self._context_cache.clear()
        
        super()._cleanup_memory()
```

## Performance Troubleshooting

### 1. Common Performance Issues

#### Slow Response Times

**Symptoms:**

- Response times > 5 seconds
- High CPU usage
- Timeout errors

**Causes & Solutions:**

```python
# 1. LLM Timeout
if "timeout" in str(error):
    # Solution: Increase timeout or optimize LLM configuration
    llm_config['timeout'] = 30  # seconds

# 2. Tool Execution Slow
if "tool" in str(error):
    # Solution: Optimize tool execution or add caching
    tool_cache = {}

# 3. Memory Pressure
if "memory" in str(error):
    # Solution: Increase memory limits or optimize trimming
    config['max_history_pairs'] = 50  # Lower limit
```

#### High Memory Usage

**Symptoms:**

- Memory usage > 80% of available
- Out of memory errors
- System slowdown

**Solutions:**

```python
# 1. Increase trimming frequency
chat_loop.config.trim_threshold = 1.2  # More aggressive

# 2. Reduce history limits
chat_loop.config.max_history_pairs = 50  # Lower limit

# 3. Enable aggressive cleanup
class AggressiveCleanup(ChatLoop):
    def _cleanup_memory(self) -> None:
        gc.collect()  # Force garbage collection
        super()._cleanup_memory()
```

#### Performance Regressions

**Symptoms:**

- Gradual performance degradation
- Increased response times over time
- Memory leaks

**Detection & Resolution:**

```python
def detect_performance_regression():
    # Compare current performance with baseline
    current_stats = run_benchmark()
    baseline_stats = load_baseline()
    
    for metric, current_value in current_stats.items():
        baseline_value = baseline_stats.get(metric, current_value)
        regression = (current_value - baseline_value) / baseline_value
        
        if regression > 0.1:  # 10% regression
            alert_regression(metric, regression)
```

### 2. Performance Debugging

#### Debug Mode

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Enable performance debugging
os.environ['VERBOSE_LOGGING'] = 'true'
os.environ['SHOW_TOOL_DETAILS'] = 'true'

# Custom performance debugging
class DebugChatLoop(ChatLoop):
    def _monitor_performance(self, operation: str, start_time: float):
        elapsed = time.time() - start_time
        
        if elapsed > 1.0:
            print(f"üêå SLOW OPERATION DETECTED:")
            print(f"   Operation: {operation}")
            print(f"   Duration: {elapsed:.3f}s")
            print(f"   Memory: {self._get_memory_usage():.2f}MB")
            print(f"   Thread: {threading.current_thread().ident}")
            
            # Stack trace for debugging
            import traceback
            traceback.print_stack()
        
        super()._monitor_performance(operation, start_time)
```

#### Performance Profiling

```python
import cProfile
import pstats

def profile_chat_operation():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Run operation
    chat_loop = ChatLoop()
    response = chat_loop.run_iteration("test input")
    
    profiler.disable()
    
    # Analyze results
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 functions
```

## Performance Best Practices

### 1. Development Guidelines

- **Monitor Performance**: Always enable performance monitoring during development
- **Test Memory Usage**: Regularly test with large conversations
- **Profile Operations**: Use profiling tools to identify bottlenecks
- **Set Baselines**: Establish performance baselines for regression testing

### 2. Production Guidelines

- **Monitor Continuously**: Set up automated performance monitoring
- **Alert on Issues**: Configure alerts for performance degradation
- **Regular Benchmarks**: Run benchmarks regularly to detect issues
- **Capacity Planning**: Monitor resource usage for scaling decisions

### 3. Optimization Guidelines

- **Measure First**: Always measure before optimizing
- **Optimize Bottlenecks**: Focus on the slowest operations
- **Test Thoroughly**: Verify optimizations don't break functionality
- **Document Changes**: Keep record of performance optimizations

---

*This performance guide provides comprehensive information for optimizing and monitoring the Chat Loop System. For specific performance issues, consult the troubleshooting section or reach out to the development team.*
